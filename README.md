# MarkovMath — A formal mathematics toolkit for Markov processes on general state spaces (with differentiable extensions)

MarkovMath is a research-oriented codebase for expressing and testing core objects from **probability on general state spaces** in a way that is:

* **explicit** about the underlying mathematical structures (state space, σ-algebra, measures, kernels),
* **composable** (build processes from kernels, build measurable sets from generators),
* **testable** (Monte Carlo “contract tests” for axioms and expected identities),
* and extensible toward **differentiable algorithms** (gradients of expectations through stochastic dynamics).

The long-term goal is to provide a clean “mathematical backbone” you can use to implement and verify constructions from modern Markov process theory, Dirichlet form theory, and potential theory.

---

## Project aims

This project aims to cover (definitions, constructions, and key results needed for):

* **Markov processes** on **general state spaces** (standard Borel / Polish settings)
* **Symmetric Markov processes** (as associated to symmetric Dirichlet forms)
* **Hunt processes** (strong Markov + quasi-left-continuity, right-continuous paths, etc.)
* **(Non-symmetric) Dirichlet forms** and associated semigroups/resolvents
* **Potential theory** for Markov processes
* **Capacities** (Choquet capacities, polar sets, quasi-everywhere statements)
* **Resolvents** and their relationships to semigroups, generators, and potentials

In addition, the project aims to encode the **theorems/lemmas/definitions** required to move between:

* kernel-based definitions (Markov kernels, transition functions),
* analytic objects (forms, generators, semigroups),
* and potential-theoretic objects (excessive functions, resolvents, capacities).

The philosophy is: *represent the objects in code with clear interfaces to follow mathematics and statistic, document the math contract each interface implies, then validate implementations with lightweight tests and examples.*

---

## Current scope (what exists today)

### Core interfaces

The code defines a small set of abstractions that mirror common mathematical objects:

* **State/Space / MetricSpace**: a state type and a distance (when applicable)
* **Event / MeasurableSpace**: events as measurable sets; Borel-like construction via generators
* **Measure / ProbabilityMeasure**: measures on events (often sample-only in practice)
* **Sampler**: sampling capability for simulation-based workflows
* **MarkovKernel**: transition kernel returning a “law” (sampler) given a current state
* **MarkovProcess**: initial law + kernel, with `sample_path` for simulation

### Event language (finite Borel fragment)

For Polish/standard Borel spaces, Borel sets are generated by open sets; in metric spaces, open balls are convenient generators. The project includes an “event AST” (abstract syntax tree) for building sets from:

* open balls (generators)
* complement / union / intersection (boolean operations)

This yields a **finite, computable fragment** of the Borel σ-algebra useful for testing and experimentation (not a full enumeration of all Borel sets).

### Contract checks (Monte Carlo)

Because Python cannot enforce measure-theoretic axioms at the type level, the project uses **contract tests**:

* metric sanity (symmetry, triangle inequality on sampled points)
* kernel sanity (sampling validity; basic consistency checks via test functions)
* measure-like sanity on finite event families (monotonicity/additivity heuristics)

These tests **don’t** prove theorems, but they catch implementation bugs early and make the abstractions usable.

---

## Mathematical positioning

### General state spaces

The intended baseline setting is **standard Borel / Polish spaces**, where:

* measurable sets are typically the **Borel σ-algebra**,
* Markov kernels are measurable in the state variable,
* many results (regular conditional probabilities, disintegrations, etc.) behave well.

### Symmetry, Dirichlet forms, and Hunt processes

The planned analytic layer is:

* Dirichlet forms (symmetric and non-symmetric)
* semigroups and resolvents
* generators and domains
* quasi-regularity conditions leading to Hunt processes
* potentials, excessive functions, capacities, polar sets

The code will treat these as structured objects whose properties are **contracts** backed by:

* definitions and stated assumptions,
* verification where possible in special cases,
* regression tests based on known examples (Brownian motion, OU process, jump processes, etc.).

---

## Roadmap

### 1) Markov process theory layer

* transition function (P_t), semigroup (T_t) on functions
* strong Markov property objects (stopping times, shift operators)
* sample-path properties (cadlag, right continuity)
* Hunt process conditions and constructions from kernels/semigroups

### 2) Dirichlet form layer

* bilinear forms (\mathcal{E}(u,v)) on (L^2(E,m))
* symmetric and non-symmetric forms; sector condition
* associated semigroup and resolvent
* quasi-regularity and process association

### 3) Potential theory layer

* resolvent (U_\alpha), excessive functions, potentials
* capacity of sets, quasi-continuous versions, polar sets
* fine topology, hitting probabilities, equilibrium potentials (in examples)

### 4) Examples library

* finite-state chains (exact measures)
* ( \mathbb{R}^d ) diffusions (via discretization)
* jump processes / Lévy-type examples (as feasible)
* explicit Dirichlet-form examples where capacities are computable or estimable

---

## Differentiable algorithms extension

After the “math backbone” is stable, the project will extend toward **differentiable algorithms**: methods to compute/estimate gradients of objectives involving stochastic systems.

### Core objective type

Many learning/inference problems reduce to:
[
J(\theta) = \mathbb{E}\big[f(X^\theta)\big],
]
where (X^\theta) may be:

* a Markov chain after (T) steps,
* a discretized SDE path,
* or the output of a stochastic simulator.

The differentiable extension aims to provide tools to estimate:
[
\nabla_\theta J(\theta).
]

### Gradient estimation methods (planned)

* **Score-function / likelihood-ratio estimators** (REINFORCE-style): works for discrete chains, high variance → needs variance reduction.
* **Pathwise / reparameterization gradients**: when (X_{t+1} = F_\theta(X_t,\varepsilon_t)) with fixed noise; enables backprop through simulation.
* **Sensitivity analysis for ergodic chains**: gradients of stationary expectations via Poisson equation / regenerative methods.
* **SDE sensitivities**: discretized dynamics, stochastic adjoints; links to stochastic flows and Malliavin-style ideas (as needed for advanced cases).
* **Differentiating through inference algorithms**: e.g. MCMC/SMC/VI steps as differentiable programs (where appropriate and well-defined).

The goal is to connect rigorous Markov process structure (kernels, resolvents, semigroups) with practical gradient-based optimization workflows.

---

## Design principles

* **Interfaces mirror math**: objects are named and structured like their mathematical counterparts.
* **Separation of concerns**: sampling vs evaluation, topology vs measurable structure, kernel vs process.
* **Contracts are explicit**: many axioms can’t be enforced; they are stated clearly and tested heuristically.
* **Small, composable pieces**: you can swap metrics, kernels, or event generators without rewriting everything.
* **Examples as truth anchors**: each new concept should come with at least one “known” example.

---

## Getting started (quick demo)

...

(See the demo in the main script for a concrete example.)

---

## Status

This project is an evolving research codebase. Some components are currently “formal interfaces + examples + tests”, and later layers (Dirichlet forms / capacities / resolvents) are planned extensions.

Contributions and refactors should preserve:

* clear mathematical intent,
* explicit contracts,
* and reproducible examples.
